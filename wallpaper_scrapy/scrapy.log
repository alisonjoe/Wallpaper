2024-02-17 20:29:38 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:29:38 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:30:02 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:30:02 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:30:02 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:30:02 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:30:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:30:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:30:02 [scrapy.extensions.telnet] INFO: Telnet Password: 42eacf92cd027bb0
2024-02-17 20:30:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:30:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 '
               'Firefox/118.0'}
2024-02-17 20:30:02 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:30:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:30:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:30:02 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:30:02 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:30:02 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:30:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:30:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:30:02 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:30:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:30:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:30:09 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 35, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:30:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:30:10 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 35, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:30:10 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:30:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1748,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 159249,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 7.621343,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 30, 10, 581166, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63586304,
 'memusage/startup': 63586304,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 30, 2, 959823, tzinfo=datetime.timezone.utc)}
2024-02-17 20:30:10 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:31:18 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:31:18 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:31:18 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:31:18 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:31:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:31:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:31:18 [scrapy.extensions.telnet] INFO: Telnet Password: 72acc9e54adf7e98
2024-02-17 20:31:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:31:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 '
               'Safari/537.36'}
2024-02-17 20:31:19 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:31:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:31:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:31:19 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:31:19 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:31:19 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:31:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:31:19 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:31:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:31:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:31:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:31:22 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 35, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:31:22 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 35, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:31:22 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:31:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1993,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 159405,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.089971,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 31, 22, 296270, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63524864,
 'memusage/startup': 63524864,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 31, 19, 206299, tzinfo=datetime.timezone.utc)}
2024-02-17 20:31:22 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:33:08 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:33:08 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:33:08 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:33:08 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:33:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:33:08 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:33:08 [scrapy.extensions.telnet] INFO: Telnet Password: 68d4b678d37dd597
2024-02-17 20:33:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:33:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'}
2024-02-17 20:33:09 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:33:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:33:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:33:09 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:33:09 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:33:09 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:33:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:33:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:33:09 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:33:10 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 35, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:33:10 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 35, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:33:10 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:33:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1963,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160607,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 1.38125,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 33, 10, 542143, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63614976,
 'memusage/startup': 63614976,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 33, 9, 160893, tzinfo=datetime.timezone.utc)}
2024-02-17 20:33:10 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:35:28 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:35:28 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:35:28 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:35:28 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:35:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:35:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:35:28 [scrapy.extensions.telnet] INFO: Telnet Password: 16e1fbaebc8a9e9d
2024-02-17 20:35:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:35:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 '
               'Firefox/117.0'}
2024-02-17 20:35:28 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:35:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:35:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:35:28 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:35:28 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:35:28 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:35:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:35:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:35:28 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:35:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:35:31 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:35:32 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:35:32 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:35:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1758,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155263,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.805368,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 35, 32, 59457, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63610880,
 'memusage/startup': 63610880,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 35, 28, 254089, tzinfo=datetime.timezone.utc)}
2024-02-17 20:35:32 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:37:19 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:37:19 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:37:19 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:37:19 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:37:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:37:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:37:19 [scrapy.extensions.telnet] INFO: Telnet Password: 9d8de8ac232ed1f1
2024-02-17 20:37:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:37:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/115.0'}
2024-02-17 20:37:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:37:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:37:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:37:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:37:20 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:37:20 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:37:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:37:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:37:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:37:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:37:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:37:21 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:37:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:37:22 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(item.get(image_urls, []),
TypeError: unhashable type: 'list'
2024-02-17 20:37:22 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:37:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1808,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 156787,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.560524,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 37, 22, 727007, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63586304,
 'memusage/startup': 63586304,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 37, 20, 166483, tzinfo=datetime.timezone.utc)}
2024-02-17 20:37:22 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:40:51 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:40:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:40:51 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:40:51 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:40:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:40:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:40:51 [scrapy.extensions.telnet] INFO: Telnet Password: 68b476e18d2c0b78
2024-02-17 20:40:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:40:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5.2 '
               'Safari/605.1.15'}
2024-02-17 20:40:52 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:40:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:40:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:40:52 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:40:52 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:40:52 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:40:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:40:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:40:52 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:40:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:40:55 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivid_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivid_id']})
KeyError: 'trivid_id'
2024-02-17 20:40:55 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivid_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivid_id']})
KeyError: 'trivid_id'
2024-02-17 20:40:55 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:40:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2003,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 157386,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.315687,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 40, 55, 586363, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63598592,
 'memusage/startup': 63598592,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 40, 52, 270676, tzinfo=datetime.timezone.utc)}
2024-02-17 20:40:55 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:41:32 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:41:32 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:41:32 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:41:32 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:41:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:41:32 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:41:32 [scrapy.extensions.telnet] INFO: Telnet Password: e42e0ed01d1d3f66
2024-02-17 20:41:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:41:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 '
               'Edg/116.0.1938.76'}
2024-02-17 20:41:32 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:41:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:41:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:41:32 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:41:32 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:41:32 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:41:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:41:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:41:32 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:41:35 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 133, in _set_url
    raise TypeError(f"Request url must be str, got {type(url).__name__}")
TypeError: Request url must be str, got tuple
2024-02-17 20:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:41:35 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 133, in _set_url
    raise TypeError(f"Request url must be str, got {type(url).__name__}")
TypeError: Request url must be str, got tuple
2024-02-17 20:41:35 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:41:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2053,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160827,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.195339,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 41, 35, 740870, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63549440,
 'memusage/startup': 63549440,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 41, 32, 545531, tzinfo=datetime.timezone.utc)}
2024-02-17 20:41:35 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:42:27 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:42:27 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:42:27 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:42:27 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:42:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:42:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:42:27 [scrapy.extensions.telnet] INFO: Telnet Password: c655012e38731f75
2024-02-17 20:42:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:42:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 '
               'Firefox/117.0'}
2024-02-17 20:42:27 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:42:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:42:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:42:27 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:42:27 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:42:27 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:42:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:42:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:42:27 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:42:30 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 133, in _set_url
    raise TypeError(f"Request url must be str, got {type(url).__name__}")
TypeError: Request url must be str, got tuple
2024-02-17 20:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:42:31 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 133, in _set_url
    raise TypeError(f"Request url must be str, got {type(url).__name__}")
TypeError: Request url must be str, got tuple
2024-02-17 20:42:31 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:42:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1748,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155263,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.606398,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 42, 31, 594148, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63524864,
 'memusage/startup': 63524864,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 42, 27, 987750, tzinfo=datetime.timezone.utc)}
2024-02-17 20:42:31 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:43:48 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:43:48 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:43:48 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:43:48 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:43:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:43:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:43:48 [scrapy.extensions.telnet] INFO: Telnet Password: 6f53f7f51dbb8263
2024-02-17 20:43:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:43:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 '
               'OPR/101.0.0.0'}
2024-02-17 20:43:48 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:43:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:43:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:43:48 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:43:48 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:43:48 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:43:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:43:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:43:48 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:43:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:43:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:43:51 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:43:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:43:51 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:43:51 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:43:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2033,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 157809,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.666794,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 43, 51, 449803, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63614976,
 'memusage/startup': 63614976,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 43, 48, 783009, tzinfo=datetime.timezone.utc)}
2024-02-17 20:43:51 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:48:13 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:48:13 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:48:13 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:48:13 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:48:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:48:13 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:48:13 [scrapy.extensions.telnet] INFO: Telnet Password: 1c262195b3f6f3a5
2024-02-17 20:48:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:48:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/118.0'}
2024-02-17 20:48:13 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:48:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:48:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:48:14 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:48:14 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:48:14 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:48:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:48:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:48:14 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:48:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:48:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:48:16 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:48:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:48:16 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:48:16 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:48:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1808,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155949,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.656613,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 48, 16, 802539, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63582208,
 'memusage/startup': 63582208,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 48, 14, 145926, tzinfo=datetime.timezone.utc)}
2024-02-17 20:48:16 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:48:44 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:48:44 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:48:44 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:48:44 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:48:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:48:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:48:44 [scrapy.extensions.telnet] INFO: Telnet Password: 14260fe33293fb53
2024-02-17 20:48:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:48:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/117.0.0.0 Safari/537.36'}
2024-02-17 20:48:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:48:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:48:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:48:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:48:44 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:48:44 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:48:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:48:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:48:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:48:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:48:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:48:46 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:48:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:48:47 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 36, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:48:47 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:48:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1913,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160607,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.791246,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 48, 47, 173323, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63549440,
 'memusage/startup': 63549440,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 48, 44, 382077, tzinfo=datetime.timezone.utc)}
2024-02-17 20:48:47 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:50:23 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:50:23 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:50:23 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:50:23 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:50:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:50:23 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:50:23 [scrapy.extensions.telnet] INFO: Telnet Password: db610ae6c9b2fc57
2024-02-17 20:50:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:50:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 '
               'Edg/116.0.1938.76'}
2024-02-17 20:50:24 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:50:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:50:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:50:24 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:50:24 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:50:24 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:50:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:50:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:50:24 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:50:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:50:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:50:26 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:50:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:50:26 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:50:26 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:50:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2053,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160667,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.540825,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 50, 26, 936866, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63606784,
 'memusage/startup': 63606784,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 50, 24, 396041, tzinfo=datetime.timezone.utc)}
2024-02-17 20:50:26 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:51:20 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:51:20 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:51:20 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:51:20 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:51:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:51:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:51:20 [scrapy.extensions.telnet] INFO: Telnet Password: 533130c43db1fb81
2024-02-17 20:51:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:51:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) '
               'Gecko/20100101 Firefox/102.0'}
2024-02-17 20:51:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:51:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:51:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:51:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:51:20 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:51:20 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:51:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:51:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:51:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:51:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:51:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:51:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:51:23 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:51:23 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:51:23 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:51:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1808,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 156969,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.341531,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 51, 23, 54199, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63557632,
 'memusage/startup': 63557632,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 51, 20, 712668, tzinfo=datetime.timezone.utc)}
2024-02-17 20:51:23 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:52:41 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:52:41 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:52:41 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:52:41 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:52:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:52:41 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:52:41 [scrapy.extensions.telnet] INFO: Telnet Password: 2d9e0fb126e48e1a
2024-02-17 20:52:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:52:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/115.0.0.0 Safari/537.36'}
2024-02-17 20:52:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:52:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:52:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:52:42 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:52:42 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:52:42 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:52:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:52:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:52:42 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:52:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:52:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:52:43 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:52:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:52:45 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 38, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:52:45 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:52:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1913,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160425,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.091829,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 52, 45, 154547, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63213568,
 'memusage/startup': 63213568,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 52, 42, 62718, tzinfo=datetime.timezone.utc)}
2024-02-17 20:52:45 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 20:54:50 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 20:54:50 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 20:54:50 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 20:54:50 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 20:54:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 20:54:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 20:54:50 [scrapy.extensions.telnet] INFO: Telnet Password: acc13ce6155ce7f4
2024-02-17 20:54:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 20:54:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) '
               'Gecko/20100101 Firefox/102.0'}
2024-02-17 20:54:50 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 20:54:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 20:54:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 20:54:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 20:54:51 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 20:54:51 [scrapy.core.engine] INFO: Spider opened
2024-02-17 20:54:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 20:54:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 20:54:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 20:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 20:54:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:54:53 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:54:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 20:54:54 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 20:54:54 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 20:54:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1808,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 156969,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 3.301458,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 12, 54, 54, 499460, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63574016,
 'memusage/startup': 63574016,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 12, 54, 51, 198002, tzinfo=datetime.timezone.utc)}
2024-02-17 20:54:54 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:00:57 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:00:57 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:00:57 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:00:57 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:00:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:00:57 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:00:57 [scrapy.extensions.telnet] INFO: Telnet Password: 3056fb7c7bd7fddd
2024-02-17 21:00:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:00:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 '
               'Edg/117.0.2045.31'}
2024-02-17 21:00:57 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:00:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:00:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:00:58 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:00:58 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:00:58 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:00:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:00:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:00:58 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:00:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 21:01:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:01:01 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:01:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:01:03 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 41, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:01:03 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:01:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2053,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 160645,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 5.249742,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 1, 3, 344449, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 2970,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 6,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63647744,
 'memusage/startup': 63647744,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 0, 58, 94707, tzinfo=datetime.timezone.utc)}
2024-02-17 21:01:03 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:04:44 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:04:44 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:04:44 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:04:44 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:04:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:04:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:04:44 [scrapy.extensions.telnet] INFO: Telnet Password: 33e4a2f24f23dfb6
2024-02-17 21:04:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:04:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/115.0'}
2024-02-17 21:04:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:04:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:04:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:04:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:04:44 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:04:44 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:04:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:04:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:04:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:04:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 21:04:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:04:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://cn.bing.com/robots.txt> from <GET https://bing.com/robots.txt>
2024-02-17 21:04:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/robots.txt> (referer: None)
2024-02-17 21:04:47 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg>
2024-02-17 21:04:47 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:04:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:04:48 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:04:48 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:04:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 1,
 'downloader/request_bytes': 2596,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 3,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 159106,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/301': 1,
 'elapsed_time_seconds': 4.17064,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 4, 48, 814690, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 5940,
 'httpcompression/response_count': 2,
 'item_dropped_count': 2,
 'item_dropped_reasons_count/DropItem': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 5,
 'memusage/max': 63574016,
 'memusage/startup': 63574016,
 'response_received_count': 4,
 'robotstxt/forbidden': 1,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 4, 44, 644050, tzinfo=datetime.timezone.utc)}
2024-02-17 21:04:48 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:06:40 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:06:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:06:40 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:06:40 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:06:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:06:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:06:40 [scrapy.extensions.telnet] INFO: Telnet Password: 40d55dc1e1c62e69
2024-02-17 21:06:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:06:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64; rv:102.0) Gecko/20100101 '
               'Firefox/102.0'}
2024-02-17 21:06:40 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:06:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:06:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:06:40 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:06:40 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:06:40 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:06:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:06:40 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> (referer: None)
2024-02-17 21:06:43 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 21:06:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites/.jpg']}
2024-02-17 21:06:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites/.jpg']}
2024-02-17 21:06:43 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:06:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1472,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 4123389,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 2.671998,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 6, 43, 507662, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63463424,
 'memusage/startup': 63463424,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 6, 40, 835664, tzinfo=datetime.timezone.utc)}
2024-02-17 21:06:43 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:10:48 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:10:48 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:10:48 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:10:48 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:10:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:10:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:10:48 [scrapy.extensions.telnet] INFO: Telnet Password: bfad0a5139a5a7a4
2024-02-17 21:10:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:10:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}
2024-02-17 21:10:48 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:10:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:10:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:10:48 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:10:48 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:10:48 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:10:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:10:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:10:48 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:11:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> (referer: None)
2024-02-17 21:11:04 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 21:11:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 21:11:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 21:11:05 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:11:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1677,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 4127759,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 16.188789,
 'file_count': 1,
 'file_status_count/downloaded': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 11, 5, 53946, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63541248,
 'memusage/startup': 63541248,
 'response_received_count': 3,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 10, 48, 865157, tzinfo=datetime.timezone.utc)}
2024-02-17 21:11:05 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:11:43 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:11:43 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:11:43 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:11:43 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:11:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:11:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:11:43 [scrapy.extensions.telnet] INFO: Telnet Password: 20aac2a1a2d02517
2024-02-17 21:11:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:11:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/116.0'}
2024-02-17 21:11:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:11:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:11:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:11:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:11:44 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:11:44 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:11:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:11:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:11:44 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:11:45 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:11:45 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:11:45 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:11:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1217,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153847,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.048355,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 11, 45, 339023, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63561728,
 'memusage/startup': 63561728,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 11, 44, 290668, tzinfo=datetime.timezone.utc)}
2024-02-17 21:11:45 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:12:28 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:12:28 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:12:28 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:12:28 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:12:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:12:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:12:28 [scrapy.extensions.telnet] INFO: Telnet Password: e14ff63450c52fc3
2024-02-17 21:12:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:12:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 '
               'Edg/117.0.2045.41'}
2024-02-17 21:12:29 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:12:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:12:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:12:29 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:12:29 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:12:29 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:12:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:12:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:12:29 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:12:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:12:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:12:30 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:12:30 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:12:30 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:12:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1413,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158629,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.065371,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 12, 30, 176720, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63524864,
 'memusage/startup': 63524864,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 12, 29, 111349, tzinfo=datetime.timezone.utc)}
2024-02-17 21:12:30 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:12:52 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:12:52 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:12:52 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:12:52 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:12:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:12:52 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:12:52 [scrapy.extensions.telnet] INFO: Telnet Password: fa5830f4e9ea453a
2024-02-17 21:12:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:12:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'}
2024-02-17 21:12:53 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:12:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:12:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:12:53 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:12:53 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:12:53 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:12:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:12:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:12:53 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:12:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:12:54 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:12:56 [scrapy.core.scraper] ERROR: Error processing {'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 892, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py", line 90, in process_item
    requests = arg_to_iter(self.get_media_requests(item, info))
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in get_media_requests
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/pipelines.py", line 42, in <listcomp>
    return [Request(url, meta={'platform': item['platform'], 'trivia_id': item['trivia_id']})
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 93, in __init__
    self._set_url(url)
  File "/usr/local/lib/python3.11/site-packages/scrapy/http/request/__init__.py", line 143, in _set_url
    raise ValueError(f"Missing scheme in request url: {self._url}")
ValueError: Missing scheme in request url: h
2024-02-17 21:12:56 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:12:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1341,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158047,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.567626,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 12, 56, 54306, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63434752,
 'memusage/startup': 63434752,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 12, 53, 486680, tzinfo=datetime.timezone.utc)}
2024-02-17 21:12:56 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:32:41 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:32:41 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:32:41 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:32:41 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:32:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:32:41 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:32:41 [scrapy.extensions.telnet] INFO: Telnet Password: 9cdad1c357b2abda
2024-02-17 21:32:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:32:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 '
               'Safari/537.36'}
2024-02-17 21:32:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:32:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:32:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:32:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:32:41 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:32:41 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:32:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:32:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:32:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:32:44 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:32:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:32:45 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:32:45 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:32:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1365,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158420,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 3.470817,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 32, 45, 445972, tzinfo=datetime.timezone.utc),
 'item_dropped_count': 2,
 'item_dropped_reasons_count/DropItem': 2,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'log_count/WARNING': 5,
 'memusage/max': 63504384,
 'memusage/startup': 63504384,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 32, 41, 975155, tzinfo=datetime.timezone.utc)}
2024-02-17 21:32:45 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:34:24 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:34:24 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:34:24 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:34:24 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:34:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:34:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:34:24 [scrapy.extensions.telnet] INFO: Telnet Password: 56b3106908e2893a
2024-02-17 21:34:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:34:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/116.0'}
2024-02-17 21:34:24 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:34:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:34:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:34:25 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:34:25 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:34:25 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:34:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:34:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:34:25 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:34:28 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:34:28 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:34:28 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:34:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1217,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153847,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 3.372316,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 34, 28, 645826, tzinfo=datetime.timezone.utc),
 'item_dropped_count': 2,
 'item_dropped_reasons_count/DropItem': 2,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'log_count/WARNING': 5,
 'memusage/max': 63471616,
 'memusage/startup': 63471616,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 34, 25, 273510, tzinfo=datetime.timezone.utc)}
2024-02-17 21:34:28 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:35:34 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:35:34 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:35:34 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:35:34 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:35:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:35:34 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:35:34 [scrapy.extensions.telnet] INFO: Telnet Password: 8c519e4836abd97b
2024-02-17 21:35:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:35:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) '
               'Gecko/20100101 Firefox/117.0'}
2024-02-17 21:35:35 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:35:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:35:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:35:35 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:35:35 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:35:35 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:35:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:35:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:35:35 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:35:37 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:35:38 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:35:38 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:35:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1209,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 154072,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 3.065125,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 35, 38, 602752, tzinfo=datetime.timezone.utc),
 'item_dropped_count': 2,
 'item_dropped_reasons_count/DropItem': 2,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'log_count/WARNING': 5,
 'memusage/max': 63459328,
 'memusage/startup': 63459328,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 35, 35, 537627, tzinfo=datetime.timezone.utc)}
2024-02-17 21:35:38 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:37:00 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:37:00 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:37:00 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:37:00 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:37:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:37:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:37:00 [scrapy.extensions.telnet] INFO: Telnet Password: 0da88f0944057138
2024-02-17 21:37:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:37:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64; rv:102.0) Gecko/20100101 '
               'Firefox/102.0'}
2024-02-17 21:37:01 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:37:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:37:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:37:01 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:37:01 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:37:01 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:37:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:37:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:37:01 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:37:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:37:02 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:37:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:37:03 [scrapy.core.scraper] WARNING: Dropped: Item contains no images
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': 'https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg', 'trivia_id': 'HPQuiz_20240217_LakeDolomites'}
2024-02-17 21:37:03 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:37:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1177,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153600,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.891911,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 37, 3, 170744, tzinfo=datetime.timezone.utc),
 'item_dropped_count': 2,
 'item_dropped_reasons_count/DropItem': 2,
 'log_count/DEBUG': 5,
 'log_count/INFO': 10,
 'log_count/WARNING': 5,
 'memusage/max': 63492096,
 'memusage/startup': 63492096,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 37, 1, 278833, tzinfo=datetime.timezone.utc)}
2024-02-17 21:37:03 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:39:05 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:39:05 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:39:05 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:39:05 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:39:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:39:05 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:39:05 [scrapy.extensions.telnet] INFO: Telnet Password: 5c2bc497b763e172
2024-02-17 21:39:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:39:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 '
               'Firefox/117.0'}
2024-02-17 21:39:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:39:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-02-17 21:39:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:39:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:39:06 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:39:06 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:39:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:39:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:39:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:39:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> (referer: None)
2024-02-17 21:39:37 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 21:39:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 21:40:06 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 1 items (at 1 items/min)
2024-02-17 21:40:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> (referer: None)
2024-02-17 21:40:41 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 21:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 21:40:41 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:40:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1755,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 8091481,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 95.186431,
 'file_count': 2,
 'file_status_count/downloaded': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 40, 41, 729076, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 11,
 'log_count/INFO': 11,
 'log_count/WARNING': 3,
 'memusage/max': 77643776,
 'memusage/startup': 63463424,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 39, 6, 542645, tzinfo=datetime.timezone.utc)}
2024-02-17 21:40:41 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 21:54:49 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 21:54:50 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 21:54:50 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 21:54:50 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 21:54:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 21:54:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 21:54:50 [scrapy.extensions.telnet] INFO: Telnet Password: a780da93be217d30
2024-02-17 21:54:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 21:54:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 '
               'Firefox/118.0'}
2024-02-17 21:54:50 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 21:54:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 21:54:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 21:54:50 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 21:54:50 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 21:54:50 [scrapy.core.engine] INFO: Spider opened
2024-02-17 21:54:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 21:54:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 21:54:50 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 21:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:54:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 21:54:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> (referer: None)
2024-02-17 21:54:53 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 21:54:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 21:55:50 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 1 items (at 1 items/min)
2024-02-17 21:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> (referer: None)
2024-02-17 21:55:58 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 21:55:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 21:55:58 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 21:55:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1755,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 8091706,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 67.576547,
 'file_count': 2,
 'file_status_count/downloaded': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 13, 55, 58, 155815, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 11,
 'log_count/INFO': 11,
 'log_count/WARNING': 3,
 'memusage/max': 74158080,
 'memusage/startup': 63488000,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 13, 54, 50, 579268, tzinfo=datetime.timezone.utc)}
2024-02-17 21:55:58 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:07:26 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:07:26 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:07:26 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:07:26 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:07:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:07:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:07:26 [scrapy.extensions.telnet] INFO: Telnet Password: 2c6e00aca9056782
2024-02-17 22:07:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:07:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 '
               'Safari/605.1.15'}
2024-02-17 22:07:26 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:07:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:07:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:07:26 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:07:26 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:07:26 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:07:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:07:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:07:26 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:07:29 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:07:29 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:07:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:07:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:07:29 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:07:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1365,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153080,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.390574,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 7, 29, 247333, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63492096,
 'memusage/startup': 63492096,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 7, 26, 856759, tzinfo=datetime.timezone.utc)}
2024-02-17 22:07:29 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:09:25 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:09:25 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:09:25 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:09:25 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:09:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:09:25 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:09:25 [scrapy.extensions.telnet] INFO: Telnet Password: 11ff5f47f4d852fd
2024-02-17 22:09:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:09:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 '
               'Safari/605.1.15'}
2024-02-17 22:09:26 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:09:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:09:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:09:26 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:09:26 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:09:26 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:09:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:09:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:09:26 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:09:27 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:09:27 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:09:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:09:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:09:27 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:09:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1365,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 152864,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.470391,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 9, 27, 827794, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63492096,
 'memusage/startup': 63492096,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 9, 26, 357403, tzinfo=datetime.timezone.utc)}
2024-02-17 22:09:27 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:10:51 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:10:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:10:51 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:10:51 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:10:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:10:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:10:51 [scrapy.extensions.telnet] INFO: Telnet Password: a4068b4daaccb520
2024-02-17 22:10:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:10:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 '
               'Edg/116.0.1938.76'}
2024-02-17 22:10:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:10:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:10:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:10:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:10:51 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:10:51 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:10:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:10:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:10:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:10:53 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:10:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:10:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:10:53 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:10:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:10:53 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:10:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1413,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 157137,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.874846,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 10, 53, 865460, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63430656,
 'memusage/startup': 63430656,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 10, 51, 990614, tzinfo=datetime.timezone.utc)}
2024-02-17 22:10:53 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:14:55 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:14:55 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:14:55 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:14:55 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:14:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:14:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:14:55 [scrapy.extensions.telnet] INFO: Telnet Password: 34b3b9865302b945
2024-02-17 22:14:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:14:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 '
               'OPR/101.0.0.0'}
2024-02-17 22:14:55 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:14:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:14:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:14:55 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:14:55 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:14:55 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:14:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:14:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:14:55 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:14:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:14:57 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:14:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:14:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:14:58 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:14:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:14:58 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:14:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1397,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155705,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.554578,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 14, 58, 470487, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63475712,
 'memusage/startup': 63475712,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 14, 55, 915909, tzinfo=datetime.timezone.utc)}
2024-02-17 22:14:58 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:19:40 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:19:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:19:40 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:19:40 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:19:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:19:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:19:40 [scrapy.extensions.telnet] INFO: Telnet Password: e83bbd936a081b70
2024-02-17 22:19:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:19:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 '
               'Edg/117.0.2045.43'}
2024-02-17 22:19:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:19:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:19:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:19:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:19:41 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:19:41 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:19:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:19:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:19:41 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:19:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:19:43 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:19:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:19:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:19:43 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:19:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:19:43 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:19:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1413,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158629,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.818861,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 19, 43, 981692, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63500288,
 'memusage/startup': 63500288,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 19, 41, 162831, tzinfo=datetime.timezone.utc)}
2024-02-17 22:19:43 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:21:51 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:21:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:21:51 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:21:51 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:21:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:21:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:21:51 [scrapy.extensions.telnet] INFO: Telnet Password: 293948c809283099
2024-02-17 22:21:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:21:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/117.0'}
2024-02-17 22:21:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:21:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:21:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:21:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:21:51 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:21:51 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:21:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:21:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:21:51 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:21:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:21:52 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:21:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:21:52 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method MarkdownMiddleware.files_downloaded of <wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware object at 0x108a4fc50>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/usr/local/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/markdownmiddlewares.py", line 16, in files_downloaded
    self.create_md(item, spider)
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/markdownmiddlewares.py", line 43, in create_md
    with open(md_filename, 'w') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/Users/alison/WorkSpace/Wallpaper/content/blog/bing/1708179712716_HPQuiz_20240217_LakeDolomites.md'
2024-02-17 22:21:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:21:53 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:21:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:21:54 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method MarkdownMiddleware.files_downloaded of <wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware object at 0x108a4fc50>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/usr/local/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/markdownmiddlewares.py", line 16, in files_downloaded
    self.create_md(item, spider)
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/markdownmiddlewares.py", line 43, in create_md
    with open(md_filename, 'w') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/Users/alison/WorkSpace/Wallpaper/content/blog/bing/1708179714067_HPQuiz_20240217_LakeDolomites.md'
2024-02-17 22:21:54 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:21:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1217,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153847,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.44782,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 21, 54, 69518, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63496192,
 'memusage/startup': 63496192,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 21, 51, 621698, tzinfo=datetime.timezone.utc)}
2024-02-17 22:21:54 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:23:59 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:23:59 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:23:59 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:23:59 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:23:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:23:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:23:59 [scrapy.extensions.telnet] INFO: Telnet Password: 30a49118856a6a44
2024-02-17 22:23:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:23:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64; rv:102.0) Gecko/20100101 '
               'Firefox/102.0'}
2024-02-17 22:24:00 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:24:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:24:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:24:00 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:24:00 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:24:00 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:24:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:24:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:24:00 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:24:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:24:01 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:24:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:24:03 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:24:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:24:03 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:24:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1177,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155092,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.724929,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 24, 3, 216229, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63430656,
 'memusage/startup': 63430656,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 24, 0, 491300, tzinfo=datetime.timezone.utc)}
2024-02-17 22:24:03 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:35:29 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:35:29 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:35:29 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:35:29 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:35:29 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:35:29 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:35:29 [scrapy.extensions.telnet] INFO: Telnet Password: dcf849ea3b08e4f7
2024-02-17 22:35:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:35:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 '
               'Safari/537.36'}
2024-02-17 22:35:30 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:35:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:35:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:35:30 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:35:30 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:35:30 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:35:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:35:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:35:30 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:35:33 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:35:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:35:33 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:35:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:35:33 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:35:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1365,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158409,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 3.292782,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 35, 33, 886940, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63623168,
 'memusage/startup': 63623168,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 35, 30, 594158, tzinfo=datetime.timezone.utc)}
2024-02-17 22:35:33 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:37:16 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:37:17 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:37:17 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:37:17 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:37:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:37:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:37:17 [scrapy.extensions.telnet] INFO: Telnet Password: 7e2a79c13ce2dea6
2024-02-17 22:37:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:37:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 '
               'Firefox/117.0'}
2024-02-17 22:37:17 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:37:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:37:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:37:17 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:37:17 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:37:17 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:37:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:37:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:37:17 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:37:18 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:37:18 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:37:18 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:37:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1169,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153589,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.228457,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 37, 18, 899010, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63459328,
 'memusage/startup': 63459328,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 37, 17, 670553, tzinfo=datetime.timezone.utc)}
2024-02-17 22:37:18 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:38:40 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:38:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:38:40 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:38:40 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:38:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:38:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:38:40 [scrapy.extensions.telnet] INFO: Telnet Password: 55cfebb51d4cb3a0
2024-02-17 22:38:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:38:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 '
               'Safari/537.36'}
2024-02-17 22:38:40 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:38:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:38:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:38:40 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:38:40 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:38:40 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:38:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:38:40 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:38:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:38:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:38:42 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:38:42 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:38:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:38:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:38:42 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:38:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1365,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158409,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.198439,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 38, 42, 174351, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63471616,
 'memusage/startup': 63471616,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 38, 40, 975912, tzinfo=datetime.timezone.utc)}
2024-02-17 22:38:42 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:42:24 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:42:24 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:42:24 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:42:24 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:42:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:42:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:42:24 [scrapy.extensions.telnet] INFO: Telnet Password: e14ca4f0b699438b
2024-02-17 22:42:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:42:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 '
               'Firefox/118.0'}
2024-02-17 22:42:25 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:42:25 [twisted] CRITICAL: Unhandled error in Deferred:
2024-02-17 22:42:25 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 1697, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 158, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 172, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.11/site-packages/scrapy/core/engine.py", line 99, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.11/site-packages/scrapy/core/downloader/__init__.py", line 97, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 90, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 66, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/misc.py", line 79, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/markdownmiddlewares.py", line 39
    ![{item['trivia_id']}](/{item{'platform']}/{item['trivia_id']}.jpg)"""
                                                                          ^
SyntaxError: f-string: closing parenthesis ']' does not match opening parenthesis '{'
2024-02-17 22:43:02 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:43:02 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:43:02 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:43:02 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:43:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:43:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:43:02 [scrapy.extensions.telnet] INFO: Telnet Password: 8d346792a57961c3
2024-02-17 22:43:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:43:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
               'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 '
               'Safari/537.36'}
2024-02-17 22:43:03 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:43:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:43:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:43:03 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:43:03 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:43:03 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:43:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:43:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:43:03 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:43:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:43:04 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:43:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:43:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:43:05 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:43:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:43:05 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:43:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1365,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158420,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.374555,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 43, 5, 558542, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63565824,
 'memusage/startup': 63565824,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 43, 3, 183987, tzinfo=datetime.timezone.utc)}
2024-02-17 22:43:05 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:44:30 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:44:30 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:44:30 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:44:30 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:44:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:44:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:44:30 [scrapy.extensions.telnet] INFO: Telnet Password: 262c54834f8ffd06
2024-02-17 22:44:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:44:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}
2024-02-17 22:44:30 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:44:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware']
2024-02-17 22:44:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:44:31 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:44:31 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:44:31 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:44:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:44:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:44:31 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:44:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:44:32 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:44:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:44:33 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:44:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:44:33 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:44:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1341,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 157016,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.768951,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 44, 33, 959819, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63467520,
 'memusage/startup': 63467520,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 44, 31, 190868, tzinfo=datetime.timezone.utc)}
2024-02-17 22:44:33 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:51:33 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:51:33 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:51:33 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:51:33 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:51:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:51:33 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:51:33 [scrapy.extensions.telnet] INFO: Telnet Password: f99f79190ae4e5f8
2024-02-17 22:51:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:51:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 '
               'Edg/117.0.2045.43'}
2024-02-17 22:51:33 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:51:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 22:51:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:51:34 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:51:34 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:51:34 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:51:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:51:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:51:34 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:51:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:51:37 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:51:37 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:51:37 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method HugoMiddleware.files_downloaded of <wallpaper_scrapy.hugomiddlewares.HugoMiddleware object at 0x1126341d0>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/usr/local/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/hugomiddlewares.py", line 16, in files_downloaded
    self.hguo_gen_html(item, spider)
AttributeError: 'HugoMiddleware' object has no attribute 'hguo_gen_html'
2024-02-17 22:51:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:51:37 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method HugoMiddleware.files_downloaded of <wallpaper_scrapy.hugomiddlewares.HugoMiddleware object at 0x1126341d0>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/usr/local/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/alison/WorkSpace/Wallpaper/wallpaper_scrapy/wallpaper_scrapy/hugomiddlewares.py", line 16, in files_downloaded
    self.hguo_gen_html(item, spider)
AttributeError: 'HugoMiddleware' object has no attribute 'hguo_gen_html'
2024-02-17 22:51:37 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:51:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1413,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 158629,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 3.099048,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 51, 37, 207052, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63467520,
 'memusage/startup': 63467520,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 51, 34, 108004, tzinfo=datetime.timezone.utc)}
2024-02-17 22:51:37 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:52:25 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:52:25 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:52:25 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:52:25 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:52:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:52:25 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:52:25 [scrapy.extensions.telnet] INFO: Telnet Password: 32e147bbef036922
2024-02-17 22:52:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:52:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 '
               'Firefox/118.0'}
2024-02-17 22:52:25 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:52:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 22:52:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:52:25 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:52:25 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:52:25 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:52:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:52:25 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:52:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:52:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:52:26 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:52:26 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:52:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:52:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:52:27 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:52:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1169,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155081,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 1.388909,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 52, 27, 83267, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63479808,
 'memusage/startup': 63479808,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 52, 25, 694358, tzinfo=datetime.timezone.utc)}
2024-02-17 22:52:27 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 22:56:49 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 22:56:49 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 22:56:49 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 22:56:49 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 22:56:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 22:56:49 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 22:56:49 [scrapy.extensions.telnet] INFO: Telnet Password: 762b6f889587a2ce
2024-02-17 22:56:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 22:56:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) '
               'Gecko/20100101 Firefox/116.0'}
2024-02-17 22:56:49 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 22:56:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 22:56:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 22:56:50 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 22:56:50 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 22:56:50 [scrapy.core.engine] INFO: Spider opened
2024-02-17 22:56:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 22:56:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 22:56:50 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 22:56:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:56:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 22:56:52 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 22:56:52 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 22:56:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:56:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 22:57:00 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 22:57:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1217,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 153589,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 10.470875,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 14, 57, 0, 565306, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63504384,
 'memusage/startup': 63504384,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 14, 56, 50, 94431, tzinfo=datetime.timezone.utc)}
2024-02-17 22:57:00 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 23:01:06 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 23:01:06 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 23:01:06 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 23:01:06 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 23:01:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 23:01:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 23:01:06 [scrapy.extensions.telnet] INFO: Telnet Password: 06fb4ffd1dcd3082
2024-02-17 23:01:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 23:01:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}
2024-02-17 23:01:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 23:01:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 23:01:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 23:01:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 23:01:06 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 23:01:06 [scrapy.core.engine] INFO: Spider opened
2024-02-17 23:01:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 23:01:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 23:01:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 23:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:01:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> (referer: None)
2024-02-17 23:01:29 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 23:01:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:01:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> (referer: None)
2024-02-17 23:01:33 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 23:01:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:01:36 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 23:01:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2007,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 8094661,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 30.108067,
 'file_count': 2,
 'file_status_count/downloaded': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 15, 1, 36, 570719, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 11,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63475712,
 'memusage/startup': 63475712,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 15, 1, 6, 462652, tzinfo=datetime.timezone.utc)}
2024-02-17 23:01:36 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 23:05:19 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 23:05:19 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 23:05:19 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 23:05:19 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 23:05:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 23:05:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 23:05:19 [scrapy.extensions.telnet] INFO: Telnet Password: a3416b674ab47efd
2024-02-17 23:05:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 23:05:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 '
               'OPR/102.0.0.0'}
2024-02-17 23:05:19 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 23:05:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 23:05:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 23:05:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 23:05:20 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 23:05:20 [scrapy.core.engine] INFO: Spider opened
2024-02-17 23:05:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 23:05:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 23:05:20 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 23:05:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:05:22 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 23:05:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:05:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:05:29 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 23:05:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:05:33 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 23:05:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1397,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 155921,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 13.271731,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 15, 5, 33, 383295, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63520768,
 'memusage/startup': 63520768,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 15, 5, 20, 111564, tzinfo=datetime.timezone.utc)}
2024-02-17 23:05:33 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 23:06:43 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 23:06:43 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 23:06:43 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 23:06:43 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 23:06:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 23:06:43 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 23:06:43 [scrapy.extensions.telnet] INFO: Telnet Password: 44274728ec171231
2024-02-17 23:06:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 23:06:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) '
               'Gecko/20100101 Firefox/118.0'}
2024-02-17 23:06:43 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 23:06:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 23:06:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 23:06:43 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 23:06:43 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 23:06:43 [scrapy.core.engine] INFO: Spider opened
2024-02-17 23:06:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 23:06:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 23:06:43 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 23:06:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:06:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:06:46 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 23:06:46 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 23:06:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:06:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:07:07 [scrapy.core.engine] INFO: Closing spider (finished)
2024-02-17 23:07:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1233,
 'downloader/request_count': 2,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 154867,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 23.43119,
 'file_count': 2,
 'file_status_count/uptodate': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 2, 17, 15, 7, 7, 319507, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 2,
 'log_count/DEBUG': 9,
 'log_count/INFO': 10,
 'log_count/WARNING': 3,
 'memusage/max': 63479808,
 'memusage/startup': 63479808,
 'response_received_count': 2,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'splash/render.html/request_count': 2,
 'splash/render.html/response_count/200': 2,
 'start_time': datetime.datetime(2024, 2, 17, 15, 6, 43, 888317, tzinfo=datetime.timezone.utc)}
2024-02-17 23:07:07 [scrapy.core.engine] INFO: Spider closed (finished)
2024-02-17 23:08:54 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: wallpaper_scrapy)
2024-02-17 23:08:55 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.4 (main, Jun 15 2023, 07:31:19) [Clang 14.0.0 (clang-1400.0.29.202)], pyOpenSSL 22.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform macOS-12.7.1-x86_64-i386-64bit
2024-02-17 23:08:55 [scrapy.addons] INFO: Enabled addons:
[]
2024-02-17 23:08:55 [asyncio] DEBUG: Using selector: KqueueSelector
2024-02-17 23:08:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-02-17 23:08:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-02-17 23:08:55 [scrapy.extensions.telnet] INFO: Telnet Password: bccfc6babdede35b
2024-02-17 23:08:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-02-17 23:08:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'wallpaper_scrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'wallpaper_scrapy.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SPIDER_MODULES': ['wallpaper_scrapy.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/116.0.0.0 Safari/537.36'}
2024-02-17 23:08:55 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "

2024-02-17 23:08:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'wallpaper_scrapy.markdownmiddlewares.MarkdownMiddleware',
 'wallpaper_scrapy.hugomiddlewares.HugoMiddleware']
2024-02-17 23:08:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-02-17 23:08:55 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/pipelines/media.py:148: ScrapyDeprecationWarning: file_path(self, request, response=None, info=None) is deprecated, please use file_path(self, request, response=None, info=None, *, item=None)
  self._check_signature(func)

2024-02-17 23:08:55 [scrapy.middleware] INFO: Enabled item pipelines:
['wallpaper_scrapy.pipelines.WallpaperImgDownloadPipeline']
2024-02-17 23:08:55 [scrapy.core.engine] INFO: Spider opened
2024-02-17 23:08:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-02-17 23:08:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-02-17 23:08:55 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy_splash/dupefilter.py:20: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  fp = request_fingerprint(request, include_headers=include_headers)

2024-02-17 23:08:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB&ensearch=1 via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:08:57 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg> referred in <None>
2024-02-17 23:08:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB&ensearch=1>
{'platform': 'bing', 'title': 'The Pragser Wildsee in the Dolomites, South Tyrol, Italy', 'tag': 'A natural wonder', 'desc': 'The Pragser Wildsee, set among the majestic Dolomites, is an Alpine jewel also known as Lake Braies. Its crystal waters reflect the impressive peaks of the Dolomites, surrounded by green forests. Accessible via a scenic trail, the lake attracts visitors for hikes and walks during the mild seasons. In summer, it turns into a destination for relaxing boat rides, while in winter the landscape takes on unique magic. The Pragser Wildsee is a mix of natural beauty, history, and culture, with the little church of St. Vitus bearing witness to its past. An enchanting place that offers an unforgettable experience in an extraordinary alpine setting.', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_EN-CN3403215959_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
2024-02-17 23:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://cn.bing.com/?FORM=BEHPTB via http://192.168.1.105:8050/render.html> (referer: None)
2024-02-17 23:09:43 [scrapy.pipelines.files] DEBUG: File (uptodate): Downloaded image from <GET https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg> referred in <None>
2024-02-17 23:09:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://cn.bing.com/?FORM=BEHPTB>
{'platform': 'bing', 'title': '多洛米蒂山的布莱耶斯湖，南蒂罗尔，意大利', 'tag': '自然奇景', 'desc': '普拉格斯湖坐落在雄伟的多洛米蒂山脉中，是阿尔卑斯山的一颗明珠，也被称为布莱耶斯湖。湖水清澈见底，倒映着多洛米蒂山壮丽伟岸的白云岩，四周环绕着郁郁葱葱的森林。湖边有一条风景优美的小径，在气候温和的时节吸引着众多游客前来远足和散步。夏季，这里是乘船休闲的好去处；冬季，湖光山色成了一幅浓郁的瑰画散发着魅力。普拉格斯湖把自然美景、历史与文化完美融合，矗立一旁的圣维特小教堂见证了它的过去。这个“拥有世上最美的高山景观”的迷人地方将为你带来难忘的体验。', 'copyright': '© Marco Bottigelli/Getty Images', 'image_urls': ['https://bing.com/th?id=OHR.LakeDolomites_ZH-CN2317113886_UHD.jpg'], 'trivia_id': 'HPQuiz_20240217_LakeDolomites', 'image_paths': ['bing/HPQuiz_20240217_LakeDolomites.jpg']}
